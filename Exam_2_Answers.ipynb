{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam 2: Eduardo Abenza SeverÃ¡\n",
    "\n",
    "Before starting these exercises, I have executed this line of code in a Linux terminal window:\n",
    "\n",
    "> sudo docker start course-mysql\n",
    "\n",
    "## Problem 1: Controls\n",
    "\n",
    "- Write a Python script that proves that the lines of data in Germplasm.tsv, and LocusGene.tsv are in the same sequence, based on the AGI Locus Code (ATxGxxxxxx). (hint: This will help you decide how to load the data into the database)\n",
    "\n",
    "### Answer 1\n",
    "\n",
    "First, I will take a look at both *.tsv* files. In this first block of code, I'm opening **Germplasm.tsv** as **germplasm** and I am printing its content (first 1000 characters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "germplasm = open(\"Germplasm.tsv\", \"r\")\n",
    "print(germplasm.read()[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is compound by four columns, called **Locus**, **germplasm**, **phenotype** and **pubmed**. These columns, and the values in each row, are delimited by tabs. In this exercise, we are interested in the values before the first tab, because they are the AGI Locus codes.\n",
    "\n",
    "Now, we are exploring the content (first 198 characters) in the second file, **LocusGene.tsv**, through an object called **locus**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locus = open(\"LocusGene.tsv\", \"r\")\n",
    "print(locus.read()[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is compound by three columns, called **Locus**, **Gene**, **phenotype** and **pubmed**. These column names, and the values in each row, are delimited by tabs. In this exercise, also we are interested in the values before the first tab in this file, because they are the AGI Locus codes.\n",
    "\n",
    "In the next cell I'm creating **germ** and **loc** lists, which contains all lines of **germplasm** and **locus**. Each line constitutes an element in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "germplasm.seek(0)\n",
    "locus.seek(0)\n",
    "\n",
    "germ = germplasm.readlines()\n",
    "loc = locus.readlines()\n",
    "\n",
    "print(\"\\nFirst four lines in Germplasm.tsv:\\n\\n\" + str(germ[:4]) + \"\\n\\nNumber of rows: \" + str(len(germ)))\n",
    "print(\"\\n\\n\\nFirst four lines in LocusGene.tsv:\\n\\n\"+ str(loc[:4]) + \"\\n\\nNumber of rows: \" + str(len(loc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both files have 33 lines, and the first ones are headers of columns.\n",
    "\n",
    "The aim of this exercise was to determine whether the lines of these files are in the same sequence, based on the AGI Locus code. In the next piece of code I'm extracting AGI Locus codes of both files in each line, and comparing them to determine whether both AGI Locus codes are equal or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for _ in range(1, 33):\n",
    "    mog = re.search('([^\\t]+)', germ[_])\n",
    "    mol = re.search('([^\\t]+)', loc[_])\n",
    "    g, l = mog.group(1), mol.group(1)\n",
    "    print(\"Row number %i\\nGermplasm: %s, LocusGene: %s\\nAre they equal? %s\" % (_, g, l, g == l))\n",
    "    if not g==l:\n",
    "        print(\"THESE AGI LOCUS CODES ARE NOT EQUAL!\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All couples of AGI Locus code are equal.\n",
    "\n",
    "## Problem 2:  Design and create the database.  \n",
    "* It should have two tables - one for each of the two data files.\n",
    "* The two tables should be linked in a 1:1 relationship\n",
    "* you may use either sqlMagic or pymysql to build the database\n",
    "\n",
    "### Answer 2\n",
    "\n",
    "The first step is the design of the two new tables. The new **germplasm** table, as Germplasm.tsv, will have four columns and their headers will be **Locus**, **germplasm**, **phenotype** and **pubmed**. I have decided to use AGI Locus code as primary key for each row. It will look like this:\n",
    "\n",
    "<center><strong>germplasm</strong></center>\n",
    "\n",
    "   Locus  |  germplasm  |  phenotype  |  pubmed  \n",
    "  --- | --- | --- | ---\n",
    "  AT1G_ _ _ _ _ | germplasm1 |  description1  |  number1\n",
    "  AT_G_ _ _ _ _  | germplasm2 |  description2  | number2 \n",
    "  AT_G_ _ _ _ _  |  germplasm3  |  description3  |  number3\n",
    "\n",
    "\n",
    "-----------------------------\n",
    "\n",
    "On the other hand, the new **locusgene** table, as LocusGene.tsv, will have three columns and their headers will be **Locus**, **gene** and **ProteinLength**. Also, I have decided to use AGI Locus code as primary key for each row. It will look like this:\n",
    "\n",
    "<center><strong>locusgene</strong></center>\n",
    "\n",
    "   Locus  |  gene  |  ProteinLength  \n",
    "  --- | --- | --- \n",
    "   AT1G_ _ _ _ _ | gene1 |  length1\n",
    "  AT_G_ _ _ _ _  | gene2 | length2 \n",
    "   AT_G_ _ _ _ _  |  gene3  |  length3\n",
    "\n",
    "\n",
    "-----------------------------\n",
    "\n",
    "With respect to the 1:1 relationship between **germplasm** and **locusgene** tables, I showed in **Question 1** that all AGI Locus codes appear in the same sequence in both files. These two tables may be linked by the AGI Locus codes.\n",
    "\n",
    "### Creation of exam2 database\n",
    "\n",
    "Now, I'm creating a new database. After loading **cursors** from **pymysql** package, I'm beginning this exercise with the creation of a new SQL database called **Exam 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql.cursors\n",
    "\n",
    "# Connect to the database\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             charset='utf8mb4',  # Important for unusual characters\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql = \"CREATE DATABASE exam2\"\n",
    "        cursor.execute(sql)\n",
    "        sql = \"SHOW DATABASES\"\n",
    "        cursor.execute(sql)\n",
    "        print(cursor.fetchall())\n",
    "finally:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'm telling SQL I'm using the new database. Initially, it is empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql = \"USE exam2\"\n",
    "        cursor.execute(sql)\n",
    "        sql = \"SHOW TABLES\"\n",
    "        cursor.execute(sql)\n",
    "        print(cursor.fetchall())\n",
    "finally:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of germplasm table\n",
    "\n",
    "To perform this task, I'm splitting (by \\t) the column names in the first line of **germ** and I'm storing them in a list called **gcolnames**. Then, I'm creating a SQL command by concatenating all items in the list (i.e., the column names) with the characteristics of each column in an appropriate manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        gcolnames = germ[0].split(\"\\t\") \n",
    "        sql = \"\"\"CREATE TABLE germplasm( {} VARCHAR(9) NOT NULL \n",
    "        PRIMARY KEY, {} VARCHAR(25) NOT NULL, {} VARCHAR(500) NOT NULL, \n",
    "        {} INTEGER NOT NULL)\"\"\".format(gcolnames[0],gcolnames[1], gcolnames[2], gcolnames[3])\n",
    "        cursor.execute(sql)\n",
    "        sql = \"DESCRIBE germplasm\"\n",
    "        cursor.execute(sql)\n",
    "        for line in cursor.fetchall():\n",
    "            print(line)\n",
    "finally:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this block of code, we get a table with the desired characteristics.\n",
    "\n",
    "### Creation of locusgene table\n",
    "\n",
    "I'm repeating the same procedure I followed to create the **germplasm** table. I'm storing the column names of **loc** object in a new list (**lcolnames**) and I'm concatenating this column names with SQL commands in a suitable manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        lcolnames = loc[0].split(\"\\t\") \n",
    "        sql = \"\"\"CREATE TABLE locusgene( {} VARCHAR(9) NOT NULL \n",
    "        PRIMARY KEY, {} VARCHAR(25) NOT NULL, \n",
    "        {} INTEGER NOT NULL)\"\"\".format(lcolnames[0],lcolnames[1], lcolnames[2])\n",
    "        cursor.execute(sql)\n",
    "        sql = \"DESCRIBE locusgene\"\n",
    "        cursor.execute(sql)\n",
    "        for line in cursor.fetchall():\n",
    "            print(line)\n",
    "finally:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second table is also correct.\n",
    "\n",
    "## Problem 3: Fill the database\n",
    "- Using pymysql, create a Python script that reads the data from these files, and fills the database.  There are a variety of strategies to accomplish this.  I will give all strategies equal credit - do whichever one you are most confident with.\n",
    "\n",
    "### Answer 3\n",
    "\n",
    "To accomplish the objective of this exercise, I am defining a new function. The input of this function, called **sql_insert_into**, are the name of the table, the name of the original file where the values are located and the delimiter used to separate values in the original file. This simple function outputs a list with all SQL **INSERT INTO** commands that are necessary to fill the table with the data of the file.\n",
    "\n",
    "In the cell below I am defining this new function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_insert_into(table, file, delimiter):\n",
    "    \"\"\"\n",
    "    This function reads the name of the table where you want to insert the values (table, string),\n",
    "    the name of the file where the values and column names are found (file, string) and the delimiter\n",
    "    which separates values in the same row in the file. \n",
    "    At the end, it returns a list with all SQL commands you need to execute to fill the table.\n",
    "    \"\"\"\n",
    "    file = open(file, \"r\")\n",
    "    file_lines = file.readlines()\n",
    "    colnames = file_lines[0].replace(\"\\n\", \"\").split(delimiter)\n",
    "    sql_commands = [] # Empty list, which will be filled and returned when this function reaches its end.\n",
    "    for _ in range(1, len(file_lines)):\n",
    "        values = file_lines[_].replace(\"\\n\", \"\").split(delimiter)  # It takes the string in line number _,\n",
    "        # removes the final \\n and splits the list into a sublist of values, previously separated by delimiter.\n",
    "        sql_line_command = \"INSERT INTO {} ( {} ) VALUES ( '{}' );\".format(\\\n",
    "            table, \", \".join(colnames), \"', '\".join(values))\n",
    "        sql_commands.append(sql_line_command) # Appends the command to introduce values in this row to \n",
    "        # sql_commands list\n",
    "    file.close()\n",
    "    return sql_commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once defined this function, we can fill both tables with the values found in the original files.\n",
    "\n",
    "### Filling of germplasm table\n",
    "\n",
    "We give **sql_insert_into** function the required strings, and execute all SQL commands in the returned list, one by one. Finally, we check the introduced values by selecting all values in this table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        for sql in sql_insert_into(\"germplasm\", \"Germplasm.tsv\", \"\\t\"):\n",
    "            cursor.execute(sql)\n",
    "        cursor.execute(\"SELECT * FROM germplasm\")\n",
    "        for line in cursor.fetchall()[0:3]:\n",
    "            print(line)\n",
    "finally:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that all values have been added correctly to this table.\n",
    "\n",
    "### Filling of locusgene table\n",
    "\n",
    "Now, we repeat the same procedure as in the previous line of code with **locusgene** table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        for sql in sql_insert_into(\"locusgene\", \"LocusGene.tsv\", \"\\t\"):\n",
    "            cursor.execute(sql)\n",
    "        cursor.execute(\"SELECT * FROM locusgene\")\n",
    "        for line in cursor.fetchall()[0:3]:\n",
    "            print(line)\n",
    "finally:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table also looks nice!\n",
    "\n",
    "## Problem 4: Create reports, written to a file\n",
    "\n",
    "1. Create a report that shows the full, joined, content of the two database tables (including a header line)\n",
    "\n",
    "2. Create a joined report that only includes the Genes SKOR and MAA3\n",
    "\n",
    "3. Create a report that counts the number of entries for each Chromosome (AT1Gxxxxxx to AT5Gxxxxxxx)\n",
    "\n",
    "4. Create a report that shows the average protein length for the genes on each Chromosome (AT1Gxxxxxx to AT5Gxxxxxxx)\n",
    "\n",
    "When creating reports 2 and 3, remember the \"Don't Repeat Yourself\" rule! \n",
    "\n",
    "All reports should be written to **the same file**.  You may name the file anything you wish.\n",
    "\n",
    "### Answer 4\n",
    "\n",
    "In this exercise, I am creating a report that shows different operations on **exam2** database tables. To write the final tsv file, I am defining a new function. This function outputs a string with multiple lines of tab-separated values (abbreviated: *tsv-string*), after reading a DictCursor dictionary (from *pymysql*) and a previous tsv-string (if existed). At the end of this exercise, this tsv-string will be written into a tsv file to show the four operations performed in this exercise.\n",
    "\n",
    "In the next piece of code I am defining this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pymysql_to_tsv(dictCursor, tsv_string = \"\"):\n",
    "    colnames = list(dictCursor[0].keys())\n",
    "    tsv_string = \"\\t\".join(colnames) + \"\\n\" # This line of code appends\n",
    "    # the header to a new line in tsv_string\n",
    "    for row in dictCursor:\n",
    "        values = []   # A new list for each row\n",
    "        for colname in colnames:\n",
    "            values.append(str(row[colname]))   # Values are appended to \"values\" list as strings\n",
    "        tsv_string = tsv_string + \"\\t\".join(values) + \"\\n\"  # Each row is concatenated to the previous\n",
    "        # tsv_string separated by \\n, with their values separated by tabs.\n",
    "    return tsv_string + \"\\n\\n\"   # The function returns a tsv_string, isolated from the following \n",
    "    # tsv_strings by two new line symbols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full, joined content of the two database tables (including a header line)\n",
    "\n",
    "I am writing the SQL command to full join both tables by locus column. We checked in **Question 1** that there are the same AGI Locus codes in both files, so any kind of join (inner, right, left and outer join) is suitable. I am using the first one, inner join.\n",
    "\n",
    "Then, using **pymysql_to_tsv** defined in the previous block of code, we write the output of this SQL command into a string. This string will be written to a file at the end of **Question 4**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql = \"SELECT * FROM locusgene INNER JOIN germplasm ON germplasm.locus = locusgene.locus;\"\n",
    "        cursor.execute(sql)\n",
    "        tsv_string = pymysql_to_tsv(cursor.fetchall())\n",
    "        comment_1 = \"# This table contains full joined content of the two database tables, called germplasm and locusgene.\\n\\n\"\n",
    "        report = comment_1 + tsv_string\n",
    "        print(report[:400])\n",
    "                \n",
    "finally:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the **report** string we have generated is correct.\n",
    "\n",
    "#### Joined report that only includes the Genes SKOR and MAA3\n",
    "\n",
    "To achieve this, we repeat the same SQL command used in the previous question with a slight modification: it only includes the rows where the gene is SKOR or MAA3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql = \"SELECT * FROM locusgene INNER JOIN germplasm ON germplasm.locus = locusgene.locus WHERE gene IN ('SKOR', 'MAA3');\"\n",
    "        cursor.execute(sql)\n",
    "        tsv_string = pymysql_to_tsv(cursor.fetchall()) \n",
    "        comment_2 = \"# This second table contains full joined content of germplasm and locusgene tables, but only for rows with genes SKOR and MAA3.\\n\\n\"\n",
    "        report = report + comment_2 + tsv_string\n",
    "        print(report[-600:])\n",
    "                \n",
    "finally:\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the last six hundreds of characters in the **report** string, we see that it looks nice.\n",
    "\n",
    "#### Report with count of the number of entries for each Chromosome\n",
    "\n",
    "In this section, I think it is advisable to create a new table in the database. This new table is equal to **locusgene** table, with an extra column: this new column shows the chromosome number for each entry.\n",
    "\n",
    "We define a new function, slightly modifying **sql_insert_into**:\n",
    "\n",
    "- In the column names (**colnames**) list, it includes a new name: **Chromosome**.\n",
    "- In the values list (**values**), we find a new element: the character in position number 3 of AGI Locus code, i.e., the **chromosome number**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_chromosome(table, file, delimiter):\n",
    "    \"\"\"\n",
    "    This function reads the name of the table where you want to insert the values (table, string),\n",
    "    the name of the file where the values and column names are found (file, string) and the delimiter\n",
    "    which separates values in the same row in the file. \n",
    "    At the end, it returns a list with all SQL commands you need to execute to fill the table.\n",
    "    (Same code as sql_insert_into function, with small modifications to create chromosome table.)\n",
    "    \"\"\"\n",
    "    file = open(file, \"r\")\n",
    "    file_lines = file.readlines()\n",
    "    colnames = file_lines[0].replace(\"\\n\", \"\").split(delimiter)\n",
    "    colnames.append(\"Chromosome\")\n",
    "    sql_commands = [] # Empty list, which will be filled and returned when this function reaches its end.\n",
    "    for _ in range(1, len(file_lines)):\n",
    "        values = file_lines[_].replace(\"\\n\", \"\").split(delimiter)  # It takes the string in line number _,\n",
    "        # removes the final \\n and splits the list into a sublist of values, previously separated by delimiter.\n",
    "        values.append(values[0][2])\n",
    "        sql_line_command = \"INSERT INTO {} ( {} ) VALUES ( '{}' );\".format(\\\n",
    "            table, \", \".join(colnames), \"', '\".join(values))\n",
    "        sql_commands.append(sql_line_command) # Appends the command to introduce values in this row to \n",
    "        # sql_commands list\n",
    "    file.close()\n",
    "    return sql_commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining this new function, we create the new table. Chromosome column only admits integer numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        lcolnames = loc[0].split(\"\\t\")\n",
    "        sql = \"\"\"CREATE TABLE chromosome( {} VARCHAR(9) NOT NULL \n",
    "        PRIMARY KEY, {} VARCHAR(25) NOT NULL, {} INTEGER NOT NULL, \n",
    "        Chromosome INTEGER NOT NULL)\"\"\".format(lcolnames[0],lcolnames[1], lcolnames[2])\n",
    "        cursor.execute(sql)\n",
    "        sql = \"DESCRIBE chromosome\"\n",
    "        cursor.execute(sql)\n",
    "        for line in cursor.fetchall():\n",
    "            print(line)\n",
    "finally:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of this table is correct.\n",
    "\n",
    "Now, we make use of **sql_chromosome** function to fill this new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        for sql in sql_chromosome(\"chromosome\", \"LocusGene.tsv\", \"\\t\"):\n",
    "            cursor.execute(sql)\n",
    "        cursor.execute(\"SELECT * FROM chromosome\")\n",
    "        for line in cursor.fetchall()[:3]:\n",
    "            print(line)\n",
    "finally:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new function has worked properly, and the new table is already filled.\n",
    "\n",
    "Now, we can create a new table which contains two columns (number of chromosome and number of entries for that chromosome), by grouping by chromosome number and selecting the **Chromosome** column and the count of rows for each chromosome after the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql = \"SELECT Chromosome, count(*) AS Occurences FROM chromosome GROUP BY Chromosome;\"\n",
    "        cursor.execute(sql)\n",
    "        tsv_string = pymysql_to_tsv(cursor.fetchall())\n",
    "        comment_3 = \"# This table shows the count of entries in the original files for each chromosome. \" + \\\n",
    "        \"To perform this task, I have created a new table with the number of chromosome for every row, \" + \\\n",
    "        \"and I have grouped by chromosome number in order to count the number of entries.\\n\\n\"\n",
    "        report = report + comment_3 + tsv_string\n",
    "        print(report[-350:])\n",
    "                \n",
    "finally:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this piece of code appears to be what we wanted. There are only four entries for chromosomes number 1 and 2, and chromosome number 3 is the one with the highest number of entries (9).\n",
    "\n",
    "#### Report showing the average protein length for the genes on each chromosome \n",
    "\n",
    "Making use of **chromosome** table, we can obtain the average protein length for the genes on each chromosome. We group by **Chromosome** and output a table with two columns: the **Chromosome** column itself and the average protein length for genes on each chromosome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql = \"SELECT Chromosome, AVG(ProteinLength) AS 'AverageProteinLength' FROM chromosome GROUP BY Chromosome;\"\n",
    "        cursor.execute(sql)\n",
    "        tsv_string = pymysql_to_tsv(cursor.fetchall())   \n",
    "        comment_4 = \"# This last table contains the average protein length for genes on each chromosome. To \" + \\\n",
    "        \"obtain this table, I have grouped the rows in chromosome table by chromosome number and I have \" + \\\n",
    "        \"computed the average protein length on each chromosome.\\n\\n\"\n",
    "        report = report + comment_4 + tsv_string\n",
    "        print(report[-350:])\n",
    "                \n",
    "finally:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have finished the operations on tables of **exam2** database. Now, we can delete this database and write the **tsv_string** with all tables to a new file called **report.txt**. This file contains all tables, with values separated by tabs, and a little comment above all tables to explain what I have done to obtain them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(\"DROP DATABASE exam2\")\n",
    "                \n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()\n",
    "\n",
    "f = open(\"report.txt\", \"w\")\n",
    "f.write(report)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
